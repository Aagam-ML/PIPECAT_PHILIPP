#
# Copyright (c) 2024–2025, Daily
#
# SPDX-License-Identifier: BSD 2-Clause License
#

"""VA - Pipecat Voice Agent

This bot uses a cascade pipeline: Speech-to-Text → LLM → Text-to-Speech

Generated by Pipecat CLI

Required AI services:
- Deepgram (Speech-to-Text)
- Openai (LLM)
- Cartesia (Text-to-Speech)

Run the bot using::

    uv run bot.py
"""

import os

from dotenv import load_dotenv
from loguru import logger
from pipecat.audio.turn.smart_turn.local_smart_turn_v3 import LocalSmartTurnAnalyzerV3
from pipecat.audio.vad.silero import SileroVADAnalyzer
from pipecat.audio.vad.vad_analyzer import VADParams
from pipecat.frames.frames import LLMRunFrame
from pipecat.pipeline.pipeline import Pipeline
from pipecat.pipeline.runner import PipelineRunner
from pipecat.pipeline.task import PipelineParams, PipelineTask
from pipecat.processors.aggregators.llm_context import LLMContext
from pipecat.processors.aggregators.llm_response_universal import LLMContextAggregatorPair
from pipecat.processors.frameworks.rtvi import RTVIObserver, RTVIProcessor
from pipecat.runner.types import RunnerArguments, SmallWebRTCRunnerArguments
from pipecat.services.cartesia.tts import CartesiaTTSService
from pipecat.services.deepgram.stt import DeepgramSTTService
from pipecat.services.openai.llm import OpenAILLMService
from pipecat.transports.base_transport import BaseTransport, TransportParams
from pipecat.transports.smallwebrtc.connection import SmallWebRTCConnection
from pipecat.transports.smallwebrtc.transport import SmallWebRTCTransport
from pipecatcloud import PipecatSessionArguments, SmallWebRTCSessionManager
from pipecat.services.openai.base_llm import BaseOpenAILLMService
from pipecat.services.openai.llm import OpenAILLMService


load_dotenv(override=True)

VOICE_PROFILES = {
    'ADVERTISING': {
        'voice_id': os.getenv('CARTESIA_VOICE_ID_ADVERTISING'),
        'system': (
          """You are a helpful AI voice assistant with the energetic, encouraging"""
        ),
    },
    'CONVERSATIONAL': {
        'voice_id': os.getenv('CARTESIA_VOICE_ID_CONVERSATIONAL'),
        'system': (
            "You are upbeat and playful. Use warm, encouraging language and light humor."
            "Keep responses brief, personal, and interactive."
             "For most questions, answer in 1–3 short sentences. "
            "Use common contractions and conversational filler words (like 'oh,' 'well,' 'right?') to sound human."
        ),
    },
    'EMOTIVE': {
        'voice_id': os.getenv('CARTESIA_VOICE_ID_EMOTIVE'),
        'system': (
            "You are expressive and insightful."
            "Respond thoughtfully, sometimes reflecting on the user's feelings or tone."
             "For most questions, answer in 1–3 short sentences. "
        ),
    },
    'ENTERTAINMENT': {
        'voice_id': os.getenv('CARTESIA_VOICE_ID_ENTERTAINMENT'),
        'system': (
            'You are charismatic and dramatic.'
            'Use engaging storytelling, cliffhangers, and vibrant language.'
             "For most questions, answer in 1–3 short sentences. "
        ),
    },
}


CURRENT_PROFILE_KEY = "ADVERTISING"
session_manager = SmallWebRTCSessionManager(timeout_seconds=120)


async def run_bot(transport: BaseTransport):
    """Main bot logic."""
    logger.info("Starting bot")

        # Speech-to-Text service
    stt = DeepgramSTTService(api_key=os.getenv("DEEPGRAM_API_KEY"))
        
    profile = VOICE_PROFILES[CURRENT_PROFILE_KEY]
    
    print("profile",profile)

  

        # Text-to-Speech service
    tts = CartesiaTTSService(
            api_key=os.getenv("CARTESIA_API_KEY"), voice_id=profile["voice_id"],
        )

        # LLM service
    llm = OpenAILLMService(
    api_key=os.getenv("OPENAI_API_KEY"),
    params=BaseOpenAILLMService.InputParams(
            temperature=0.6,            # Response creativity (0.0-2.0)
            max_completion_tokens=150,  # Maximum response length
            frequency_penalty=0.5,      # Reduce repetition (0.0-2.0)
            presence_penalty=0.5,       # Encourage topic diversity (0.0-2.0)
        ),
    )


    # Video service (avatar)

    messages = [
    {
        "role": "system",
        "content": (
            "You are a friendly, concise AI voice assistant. "
            "Speak in natural everyday language. "
            "For most questions, answer in 1–3 short sentences. "
            "If the user asks for more detail, then elaborate."
        ),
    },
    ]

    context = LLMContext(messages)
    context.messages.append(
        {
            "role": "system",
            "content": profile["system"],
        }
    )
    
    context_aggregator = LLMContextAggregatorPair(context)

    rtvi = RTVIProcessor()
    
    @rtvi.event_handler("on_client_message")
    async def on_client_message(rtvi_proc, message):
        # message: RTVIClientMessage
        msg_type = message.type          # e.g. "set-voice"
        data = message.data or {}

        if msg_type != "set-voice":
            return

        # Accept either { profile: "friendly" } or { voice: "friendly" }
        requested = data.get("profile") or data.get("voice")
        if not requested:
            logger.warning("set-voice message without profile/voice")
            return

        if requested not in VOICE_PROFILES:
            logger.warning(f"Unknown voice profile: {requested}")
            return

        new_profile = VOICE_PROFILES[requested]
        logger.info(f"Switching to voice profile: {requested}")

        # 1) Finish current audio if any
        try:
            await tts.flush_audio()
        except Exception as e:
            logger.error(f"Error flushing audio before voice switch: {e}")

        # 2) Switch Cartesia voice
        try:
            tts.set_voice(new_profile["voice_id"])
        except Exception as e:
            logger.error(f"Error setting new Cartesia voice: {e}")
            return

        # 3) Tell the LLM about the new persona
        context.messages.append(
            {
                "role": "system",
                "content": new_profile["system"],
            }
        )

        logger.info("Voice and persona updated from client")


        # Pipeline - assembled from reusable components
    pipeline = Pipeline(
            [
                transport.input(),
                rtvi,
                stt,
                context_aggregator.user(),
                llm,
                tts,
                transport.output(),
                context_aggregator.assistant(),
            ]
        )

    task = PipelineTask(
            pipeline,
            params=PipelineParams(
                enable_metrics=True,
                enable_usage_metrics=True,
            ),
            observers=[
                RTVIObserver(rtvi),
            ],
        )

    @rtvi.event_handler("on_client_ready")
    async def on_client_ready(rtvi):
            await rtvi.set_bot_ready()
            # Kick off the conversation
            await task.queue_frames([LLMRunFrame()])

    @transport.event_handler("on_client_connected")
    async def on_client_connected(transport, client):
            logger.info("Client connected")

    @transport.event_handler("on_client_disconnected")
    async def on_client_disconnected(transport, client):
            logger.info("Client disconnected")
            await task.cancel()

    runner = PipelineRunner(handle_sigint=False)

    await runner.run(task)


async def bot(runner_args: RunnerArguments):
    """Main bot entry point."""
    # Handle Pipecat Cloud initialization for SmallWebRTC
    if isinstance(runner_args, PipecatSessionArguments):
        logger.info("Starting the bot, waiting for webrtc_connection from Pipecat Cloud")
        try:
            await session_manager.wait_for_webrtc()
        except TimeoutError as e:
            logger.error(f"Timeout waiting for WebRTC connection: {e}")
            raise
        return

    # Handle SmallWebRTC connection established
    if isinstance(runner_args, SmallWebRTCRunnerArguments):
        logger.info("Received webrtc_connection from Pipecat Cloud")
        session_manager.cancel_timeout()

    transport = None

    match runner_args:
        case SmallWebRTCRunnerArguments():
            webrtc_connection: SmallWebRTCConnection = runner_args.webrtc_connection

            transport = SmallWebRTCTransport(
                webrtc_connection=webrtc_connection,
                params=TransportParams(
                    audio_in_enabled=True,
                    audio_out_enabled=True,
                    vad_analyzer=SileroVADAnalyzer(params=VADParams(stop_secs=0.3)),
                    turn_analyzer=LocalSmartTurnAnalyzerV3(),
                ),
            )
        case _:
            logger.error(f"Unsupported runner arguments type: {type(runner_args)}")
            return

    try:
        await run_bot(transport)
    finally:
        if isinstance(runner_args, SmallWebRTCRunnerArguments):
            logger.info("Cleaning up SmallWebRTC resources")
            session_manager.complete_session()


if __name__ == "__main__":
    from pipecat.runner.run import main

    main()
